# filter_html.py
from bs4 import BeautifulSoup
import argparse, sys, re
from pathlib import Path

def normalize_ws(text: str) -> str:
    return re.sub(r"\s+", " ", text).strip()

def is_block_anchor(a_tag) -> bool:
    """Treat <a> as a standalone heading if it's not inline in p/li/td/th
    and is the only visible text within its immediate block container."""
    if a_tag.find_parent(["p", "li", "td", "th"]):
        return False
    parent = a_tag.parent
    if not parent:
        return True
    a_txt = normalize_ws(a_tag.get_text(" ", strip=True))
    parent_txt = normalize_ws(parent.get_text(" ", strip=True))
    return a_txt != "" and a_txt == parent_txt

def filter_html(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")

    # ---- header ----
    title = soup.title.get_text(strip=True) if soup.title else ""
    h1 = soup.find("h1")
    h1_text = normalize_ws(h1.get_text(" ", strip=True)) if h1 else ""

    # ---- traversal (after <h1> if present; else inside <body>) ----
    iterable = (h1.find_all_next(True) if h1 else (soup.body or soup).find_all(True))

    lines = []

    # If there is no <h1>, optionally pick a nearby heading before first <pre>
    if not h1:
        pre = soup.find("pre")
        if pre:
            for prev in pre.find_all_previous():
                if prev.name in ("span", "div", "p", "b", "strong", "h2", "h3"):
                    t = normalize_ws(prev.get_text(" ", strip=True))
                    if t:
                        lines.append(t)
                        break

    for el in iterable:
        name = (el.name or "").lower()
        txt = None

        if name in ("h2", "h3", "h4", "h5", "h6"):
            txt = normalize_ws(el.get_text(" ", strip=True))

        elif name in ("p", "li"):
            txt = normalize_ws(el.get_text(" ", strip=True))

        elif name in ("b", "strong"):
            # only keep if not inline and not inside table cells (td/th)
            if el.find_parent(["p", "li", "td", "th"]):
                pass
            else:
                txt = normalize_ws(el.get_text(" ", strip=True))

        elif name == "a":
            if is_block_anchor(el):
                txt = normalize_ws(el.get_text(" ", strip=True))

        elif name == "pre":
            # preserve monospace output exactly; also ensure a blank line before it
            if lines and lines[-1] != "":
                lines.append("")
            lines.append(el.get_text())
            lines.append("")  # blank line after block
            continue

        elif name in ("th",):
            txt = normalize_ws(el.get_text(" ", strip=True))

        elif name == "td":
            # capture table cells that start with bold/strong (section captions)
            if el.find(["b", "strong"]):
                txt = normalize_ws(el.get_text(" ", strip=True))

        # store if not empty and not a duplicate / prefix-duplicate
        if txt:
            if not lines:
                lines.append(txt)
            else:
                prev = lines[-1]
                # drop if exactly the same (case/space normalized)
                if normalize_ws(prev).lower() == txt.lower():
                    continue
                # drop previous if it is just a prefix of this line (e.g., "Vermessung:" vs
                # "Vermessung: Projektdaten transformieren")
                if prev and txt.lower().startswith(prev.lower()) and len(txt) > len(prev) + 2:
                    lines[-1] = txt
                else:
                    lines.append(txt)

    # remove any stray extra blank lines
    cleaned = []
    for i, s in enumerate(lines):
        if s == "" and (i == 0 or cleaned and cleaned[-1] == ""):
            continue
        cleaned.append(s)

    # ---- assemble output ----
    out = []
    if title:
        out.append(f"title:{title}")
    if h1_text:
        out.append(h1_text)
    if cleaned:
        out.append("")
        out.extend(cleaned)

    return "\n".join(out)

def main():
    ap = argparse.ArgumentParser(description="Filter an HTML/HTM file to plain text.")
    ap.add_argument("input")
    ap.add_argument("-o", "--output")
    args = ap.parse_args()

    html = Path(args.input).read_text(encoding="utf-8", errors="ignore")
    result = filter_html(html)

    if args.output:
        Path(args.output).write_text(result + "\n", encoding="utf-8")
    else:
        sys.stdout.write(result + "\n")

if __name__ == "__main__":
    main()