Awesome — I wrapped your `filter_html.py` into a pipeline **Step** that runs *before* chunking and writes clean `.txt` files into `paths.txt_dir`, which your `ChunkWithEmbedderTokenizerStep` already reads. Drop this file anywhere in your pipeline (e.g. `src/steps/filter_html_step.py`) and add it to your run sequence before chunking.

```python
# src/steps/filter_html_step.py
from __future__ import annotations

"""
FilterHtmlToTextStep
--------------------
Cleans raw HTML into compact, RAG-friendly plain text.
Runs BEFORE chunking and writes .txt files into paths.txt_dir.

Reads:
  paths.html_dir (or ctx.artifacts["html_dir"])  -> *.html, *.htm, *.xhtml

Writes:
  paths.txt_dir/<basename>.txt

Config it uses:
  paths.html_dir
  paths.txt_dir
"""

from pathlib import Path
from typing import Iterable
import re

from bs4 import BeautifulSoup, NavigableString

from src.pipeline.core import Step, Context
from src.pipeline.utils import iter_files, fresh_dir
from src.pipeline.utils.logging import get_logger


INLINE_TAGS = {"a","b","strong","i","em","span","code","kbd","samp","u","small","sup","sub","mark"}
SKIP_CONTAINERS = {"script","style","noscript","svg","nav","header","footer","aside"}
BREADCRUMB_HINTS = ("sie sind hier", "zu hauptinhalt springen")

def normalize_ws(text: str) -> str:
    return re.sub(r"\s+", " ", text or "").strip()

def only_inline_children(tag) -> bool:
    """True if a block contains only inline tags / text (no block children)."""
    for c in tag.children:
        if isinstance(c, NavigableString):
            continue
        if getattr(c, "name", "").lower() not in INLINE_TAGS:
            return False
    return True

def is_block_heading_anchor(a_tag) -> bool:
    """
    Headline like <div><a>Text</a></div> OR <div><span><a>Text</a></span></div>.
    We check if the *container's* visible text equals the <a>'s text.
    """
    if not a_tag or not a_tag.get_text(strip=True):
        return False
    cont = a_tag
    # climb one level if the immediate parent is an inline wrapper
    if cont.parent and getattr(cont.parent, "name", "").lower() in INLINE_TAGS:
        cont = cont.parent
    parent = cont.parent
    if not parent or getattr(parent, "name", "").lower() not in {"div","td","th"}:
        return False
    parent_txt = normalize_ws(parent.get_text(" ", strip=True))
    link_txt = normalize_ws(a_tag.get_text(" ", strip=True))
    if not parent_txt or not link_txt:
        return False
    # treat as heading when the container text is basically just the link text
    return parent_txt == link_txt and only_inline_children(parent)

def looks_like_breadcrumb(text: str) -> bool:
    lo = (text or "").lower()
    return any(h in lo for h in BREADCRUMB_HINTS)

def filter_html_string(html: str) -> str:
    """Return a compact plain-text representation of an HTML page."""
    soup = BeautifulSoup(html, "html.parser")

    # Remove obvious non-content containers to reduce noise
    for tag in soup.find_all(SKIP_CONTAINERS):
        tag.decompose()

    title = soup.title.get_text(strip=True) if soup.title else ""

    h1 = soup.find("h1")
    h1_text = normalize_ws(h1.get_text(" ", strip=True)) if h1 else ""

    # pick traversal root
    iterable = (h1.find_all_next(True) if h1 else (soup.body or soup).find_all(True))

    lines = []

    # If no <h1>, try to grab a heading immediately before first <pre>
    if not h1:
        pre = soup.find("pre")
        if pre:
            for prev in pre.find_all_previous():
                if prev.name in ("h2","h3","h4","h5","h6","div","td","th","p","b","strong","span"):
                    t = normalize_ws(prev.get_text(" ", strip=True))
                    if t and not looks_like_breadcrumb(t):
                        lines.append(t)
                        break

    for el in iterable:
        name = (el.name or "").lower()

        # Skip obvious crumbs
        if name in {"span","div"}:
            tpeek = normalize_ws(el.get_text(" ", strip=True))
            if looks_like_breadcrumb(tpeek):
                continue

        # Headings h1..h6
        if name in ("h1","h2","h3","h4","h5","h6"):
            txt = normalize_ws(el.get_text(" ", strip=True))

        # Table cells that *act* like headings
        elif name in ("th","td"):
            raw = normalize_ws(el.get_text(" ", strip=True))
            if not raw:
                continue
            if name == "th" or el.find(["b","strong"]):
                txt = raw
            else:
                continue

        # Standalone bold/strong blocks (not inside paragraphs/lis)
        elif name in ("b","strong"):
            if el.find_parent(["p","li"]):
                continue
            txt = normalize_ws(el.get_text(" ", strip=True))

        # Block-level anchor headings (e.g., <div><a>Koordinatensysteme</a></div>)
        elif name == "a" and is_block_heading_anchor(el):
            txt = normalize_ws(el.get_text(" ", strip=True))

        # Headline-ish DIVs that contain only inline nodes (no nested blocks)
        elif name == "div" and only_inline_children(el):
            txt = normalize_ws(el.get_text(" ", strip=True))
            if not txt or looks_like_breadcrumb(txt):
                continue
            if txt.lower() in {"logout","konto","einstellungen","placeholder","alle dateien"}:
                continue

        # Regular content
        elif name in ("p","li"):
            txt = normalize_ws(el.get_text(" ", strip=True))

        # Preserve formatted blocks
        elif name == "pre":
            txt = el.get_text()  # keep line breaks/spaces

        else:
            continue

        if txt and (not lines or lines[-1] != txt):
            lines.append(txt)

    # assemble output
    out = []
    if title:
        out.append(f"title:{title}")
    if h1_text:
        out.append(h1_text)
    if lines:
        out.append("")
        out.extend(lines)

    return "\n".join(out)

class FilterHtmlToTextStep(Step):
    """Convert raw HTML pages to plain text files consumed by the chunker."""
    name = "FilterHTML"

    def run(self, ctx: Context) -> None:
        log = get_logger(self.name)

        # ---- Paths
        html_root = Path(ctx.artifacts.get("html_dir") or ctx.cfg["paths"]["html_dir"])
        out_dir = fresh_dir(ctx.cfg["paths"]["txt_dir"])

        if not html_root.exists():
            log.error("Input HTML directory does not exist: %s", html_root)
            return

        # ---- Process
        count_in = 0
        count_out = 0
        exts = [".html", ".htm", ".xhtml"]
        for p in iter_files(html_root, exts=exts):
            count_in += 1
            try:
                html = p.read_text(encoding="utf-8", errors="ignore")
            except Exception as e:
                log.warning("Failed to read %s: %s", p, e)
                continue

            txt = filter_html_string(html).strip()
            if not txt:
                continue

            out_path = out_dir / (p.stem + ".txt")
            try:
                out_path.write_text(txt + "\n", encoding="utf-8")
                count_out += 1
            except Exception as e:
                log.warning("Failed to write %s: %s", out_path, e)

        log.info("Filtered HTML → %s (files in: %d, txt written: %d)", out_dir, count_in, count_out)
        ctx.artifacts["txt_dir"] = str(out_dir)
```

### How to plug it into your pipeline

* Make sure your config has:

```yaml
paths:
  html_dir: ./data/raw_html
  txt_dir: ./data/text
```

* Run order (high level):

1. `FilterHTML` (this step)
2. `ChunkWithEmbedderTokenizer` (your step) &#x20;
3. `Embed` (your `EmbedWithControlsStep`) &#x20;
4. `BuildFaissIndex`, `BuildLexicalIndex`, `HybridSearch` as needed


